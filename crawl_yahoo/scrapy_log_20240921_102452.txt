2024-09-21 10:24:53 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: crawl_yahoo)
2024-09-21 10:24:53 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.1, Platform Windows-10-10.0.22631-SP0
2024-09-21 10:24:53 [scrapy.addons] INFO: Enabled addons:
[]
2024-09-21 10:24:53 [asyncio] DEBUG: Using selector: SelectSelector
2024-09-21 10:24:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-09-21 10:24:53 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2024-09-21 10:24:53 [scrapy.extensions.telnet] INFO: Telnet Password: 022e25692759ed93
2024-09-21 10:24:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-09-21 10:24:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'crawl_yahoo',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_log_20240921_102452.txt',
 'NEWSPIDER_MODULE': 'crawl_yahoo.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['crawl_yahoo.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-09-21 10:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'rotating_proxies.middlewares.RotatingProxyMiddleware',
 'rotating_proxies.middlewares.BanDetectionMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'crawl_yahoo.middlewares.CrawlYahooDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-09-21 10:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-09-21 10:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-09-21 10:24:53 [scrapy.core.engine] INFO: Spider opened
2024-09-21 10:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-09-21 10:24:53 [my_crawler] INFO: Spider opened: my_crawler
2024-09-21 10:24:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-09-21 10:24:53 [rotating_proxies.middlewares] INFO: Proxies(good: 0, dead: 0, unchecked: 100, reanimated: 0, mean backoff time: 0s)
2024-09-21 10:25:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/robots.txt> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:25:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/robots.txt> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:25:23 [rotating_proxies.middlewares] INFO: Proxies(good: 0, dead: 0, unchecked: 100, reanimated: 0, mean backoff time: 0s)
2024-09-21 10:25:23 [rotating_proxies.expire] DEBUG: Proxy <http://8.209.255.13:3128> is GOOD
2024-09-21 10:25:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/robots.txt> (referer: None)
2024-09-21 10:25:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:25:53 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2024-09-21 10:25:53 [rotating_proxies.middlewares] INFO: Proxies(good: 1, dead: 0, unchecked: 99, reanimated: 0, mean backoff time: 0s)
2024-09-21 10:26:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2024-09-21 10:26:02 [rotating_proxies.expire] DEBUG: Proxy <http://3.229.228.77:3128> is GOOD
2024-09-21 10:26:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/> (referer: None)
2024-09-21 10:26:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/topic/latest-news/> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:26:07 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "news.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:26:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.yahoo.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', '', 'packet length too long'), ('SSL routines', '', 'record layer failure')]>]
2024-09-21 10:26:09 [rotating_proxies.expire] DEBUG: Proxy <http://8.148.23.202:9098> is GOOD
2024-09-21 10:26:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://news.yahoo.com/robots.txt> (referer: None)
2024-09-21 10:26:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/topic/economic-news/> (failed 1 times): Could not open CONNECT tunnel with proxy 43.134.68.153:3128 [{'status': 502, 'reason': b'Bad Gateway'}]
2024-09-21 10:26:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://news.yahoo.com/newsletters/> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:26:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.yahoo.com/robots.txt> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:26:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/most-people-expect-retire-67-193051193.html> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:26:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/own-home-hope-buy-one-090020148.html> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:26:23 [rotating_proxies.middlewares] INFO: Proxies(good: 3, dead: 0, unchecked: 97, reanimated: 0, mean backoff time: 0s)
2024-09-21 10:26:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/topic/premium-news> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:26:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> (failed 1 times): Could not open CONNECT tunnel with proxy 187.157.243.254:8080 [{'status': 403, 'reason': b'Forbidden'}]
2024-09-21 10:26:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/millennial-fire-couple-shares-moving-180302476.html> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:26:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:26:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://news.yahoo.com/originals/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2024-09-21 10:26:48 [rotating_proxies.expire] DEBUG: Proxy <http://190.107.232.138:999> is GOOD
2024-09-21 10:26:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/want-safe-dividend-income-2024-084800477.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:26:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/want-safe-dividend-income-2024-084800477.html>
{'title': 'Want Safe Dividend Income in 2024 and Beyond? Invest in These 3 Ultra-High-Yield Stocks.', 'content': 'If your gut tells you now is a good time to add some safe dividend payers to your investment portfolio, you\'d be wise to listen. Between geopolitical turmoil, lingering inflation, unpredictable interest rates, rising loan delinquencies, and political uncertainty, the near future may not be a great environment for some -- or maybe any -- growth stocks. However, these three high-yield dividend stocks are up to the job of providing investors with solid returns, and they should remain so indefinitely. The United States\'   is living on borrowed time. That\'s the top takeaway from the World Health Organization\'s (WHO) most recent look at the matter anyway, which suggests only 18.2% of the nation\'s adult population will be regular tobacco users (smokers, mostly) in 2025. That\'s measurably less than 2000\'s figure of 23.3%. The United States\' tobacco business may actually have more years ahead of it than you might expect, however. Also recognizing the smoking-cessation movement is slowing down, the same WHO report suggests 16.5% of U.S. adults will still be regularly using tobacco by 2030. People are picking up alternative vices like vaping and the use of e-cigarettes in droves in the meantime. The National Center for Health Statistics reports over 4% of the country\'s adults use vape products regularly, offsetting the shrinking number of smokers. Connect the dots. Given the nation\'s expected population growth between now and then (and beyond), there\'s still plenty of opportunity to turn these common consumer habits into lots of cash. The backdrop bodes well for    , parent to Philip Morris USA, which owns familiar U.S. cigarette brands like Marlboro, Virginia Slims, and others. And, even though cigarettes remain its top seller, it also owns vaping brand   and oral nicotine pouch maker Helix Innovations. These other initiatives are softening the impact of tobacco\'s slow demise on Altria, which has adopted the motto "Moving beyond smoking." By accepting the gradual but inevitable decline of the cigarette market rather than resisting it, the company can continue generating good revenue by managing -- and even steering -- the transition to other nicotine products. More important to shareholders, managing this evolution lets Altria continue producing the profits that have supported 55 straight years of annual dividend increases. It\'s important for investors to understand that there won\'t likely be any meaningful or sustainable capital appreciation here. Altria doesn\'t even appear to be trying to muster growth. Its focus is entirely on maintaining the cash flow that funds its dividend payments. With a forward yield of 7.7% and a dividend that could continue growing and being paid for decades though, that\'s not a bad trade-off. Contrary to a common assumption, not all sections of the retail industry are on the ropes. The bulk of the weakness is limited to department stores and the malls where they\'re typically found. Strip malls and neighborhood shopping centers are actually doing pretty well, catering to consumers where and how they like to shop. Enter    . It\'s not a retailer, although its fate is tied to a wide swath of that industry. It\'s a real estate investment trust (REIT), renting brick-and-mortar properties to retailers, sparing its tenants some of the financial commitments of owning all those buildings. That may still seem like a risky proposition on the surface. The landlord is still renting to companies in a retail industry that\'s being pressured by the ongoing growth of e-commerce. This overarching idea ignores a couple of important details though. One is that a great deal of retail consumption is still (for convenience and speed reasons) handled in person at stores. And the other reason? The bulk of Realty Income\'s tenants are among the retailers with the most staying power, like  ,  , 7-Eleven, and even  . Once these chains have established a brick-and-mortar presence in a location, they\'re unlikely to abandon it. That\'s what this REIT\'s dividend track record suggests anyway. Not only has it distributed its monthly (yes, monthly) payments like clockwork ever since they began in 1969, those payouts have been raised 127 times. Those who buy the stock today would be stepping in while Realty Income\'s forward dividend yield stands at 5%. Last but not least, add home appliance maker    to your list of dividend stocks to consider buying while its forward yield stands at 7%. It\'s a suggestion that might raise a few eyebrows. Even if you don\'t know for sure, intuitively, it doesn\'t seem as if there\'d be great demand for home appliances at this time. Growing competition from the likes of  , Bosch, and LG further deflates the bullish argument for owning a stake in this iconic brand name. Things may not be quite as challenging on this front as it seems they should be, though. Unlike some other large purchases, the purchase of a major home appliance can\'t always be put off. Appliances are also more affordable than cars or homes, for example, so getting financing is less of a hurdle. To this end, the Conference Board\'s consumer sentiment measure ticked higher in August specifically because -- in apparent defiance of the economic backdrop -- more U.S. consumers said they intend to purchase a refrigerator, washing machine, or TV within the next six months. It was the fourth straight month these purchasing plans improved. Investors who already know Whirlpool will likely also know that while it has continued to make its dividend payments, it hasn\'t increased them since 2022, when it raised the quarterly payout to $1.75 per share. Keep things in perspective though, its ability to maintain its payout was never in question. The decision to halt its long-established cadence of dividend growth was rooted in an abundance of caution at an extraordinary time in modern history. The COVID-19 pandemic and the ripple effects from it not only temporarily up-ended purchases of appliances, they impeded companies\' ability to manufacture them. This year\'s expected 14% revenue dip and subsequent profit setback should mark the end of these woes though. Analysts forecast that Whirlpool\'s business will turn the corner next year. In the meantime, with the stock trades down 60% from its 2021 high and is valued at less than 9 times next year\'s estimated earnings, the worst-case scenario is already priced in ... and then some. Before you buy stock in Altria Group, consider this: The   analyst team just identified what they believe are the\xa0  for investors to buy now… and Altria Group wasn’t one of them. The 10 stocks that made the cut could produce monster returns in the coming years.  provides investors with an easy-to-follow blueprint for success, including guidance on building a portfolio, regular updates from analysts, and two new stock picks each month. The service has   the return of S&P 500 since 2002*.  was originally published by The Motley Fool', 'date': '2024-09-20', 'time': '08:48:00.000', 'link': 'https://finance.yahoo.com/news/want-safe-dividend-income-2024-084800477.html'}
2024-09-21 10:26:49 [rotating_proxies.expire] DEBUG: Proxy <http://213.148.10.199:3128> is GOOD
2024-09-21 10:26:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/mortgage-rates-inch-closer-to-6-following-fed-rate-cut-160309788.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:26:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/mortgage-rates-inch-closer-to-6-following-fed-rate-cut-160309788.html>
{'title': 'Mortgage rates inch closer to 6% following Fed rate cut', 'content': 'Average 30-year fixed mortgage rates fell again this week to 6.09%, though the move wasn’t directly tied to the Federal Reserve’s rate cut on Wednesday. The average rate dropped 0.11 percentage point from a week earlier, according to Freddie Mac data released Thursday, leaving the average at the lowest level since early February 2023. Fifteen-year mortgage rates also fell, to 5.15% from 5.27% a week ago. In recent months, mortgage rates have dropped more than a percentage point in anticipation of the Fed’s move. At its meeting Wednesday, the central bank cut benchmark interest rates by 50 basis points to a range of 4.75% to 5% and indicated it plans to lower rates twice more by the end of the year. Headed into the meeting, traders were divided on how much the Fed would cut, but the central bank’s decision to make a larger reduction wasn’t enough of a surprise to move mortgage rates materially — nor is it likely to drive them   from here, said Orphe Divounguy, a senior economist at Zillow. “The markets really expected the current scenario,” Divounguy said. “Mortgage rates moved lower ahead of the Fed meeting. That has improved housing affordability.” After a very slow summer, there are signs that buyers are beginning to take notice of the lower rates.   for home purchases and refinancings jumped more than 14% from a week earlier, according to the Mortgage Bankers Association. Refinancing applications were particularly strong, more than doubling from the same period a year ago as homeowners seek to lower their monthly payments. The MBA estimated average 30-year mortgage rates at 6.15% for the week that ended on Friday. In August,   slipped 2.5% from July to an annual rate of 3.86 million, according to the National Association of Realtors. Median home prices hit $416,700 last month, a 3.1% increase from a year earlier. “Mortgage rates continued declining towards the 6% mark, reviving purchase and refinance demand for many consumers,” Sam Khater, Freddie Mac’s chief economist, said in a statement. “While mortgage rates do not directly follow moves by the Federal Reserve, this first cut in over four years will have an impact on the housing market.”', 'date': '2024-09-19', 'time': '19:52:16.000', 'link': 'https://finance.yahoo.com/news/mortgage-rates-inch-closer-to-6-following-fed-rate-cut-160309788.html'}
2024-09-21 10:26:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/brazil-trims-2024-spending-freeze-002356049.html> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:26:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/warren-buffett-could-bought-379-090600668.html> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:26:53 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 4 pages/min), scraped 2 items (at 2 items/min)
2024-09-21 10:26:53 [rotating_proxies.middlewares] INFO: Proxies(good: 5, dead: 0, unchecked: 95, reanimated: 0, mean backoff time: 0s)
2024-09-21 10:26:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:26:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:26:56 [rotating_proxies.expire] DEBUG: Proxy <http://43.134.33.254:3128> is GOOD
2024-09-21 10:26:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/sri-lankans-vote-tight-race-013000137.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:26:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/sri-lankans-vote-tight-race-013000137.html>
{'title': 'Sri Lankans Vote in Tight Race That Puts IMF Funding at Risk', 'content': '(Bloomberg) -- Sri Lanka’s 17 million voters head to the polls Saturday to elect a president two years after an economic meltdown and a historic debt default caused widespread political unrest and the ousting of the former strongman leader. Most Read from Bloomberg Voters must now choose a president who can steer the economy through a fragile recovery and finalize a debt restructuring deal that will allow the International Monetary Fund to disburse more bailout funding the South Asian island desperately needs. Although a record 38 candidates are on the ballot, the election has been a tight race between three leading candidates: incumbent President Ranil Wickremesinghe, opposition leader Sajith Premadasa, and Anura Kumara Dissanayake, a leftist politician backed by protesters who led the political uprisings in 2022. At stake is the fate of the $3 billion IMF lending program, with both Premadasa and Dissanayake vowing to renegotiate the loan conditions to ease the burden on the poor. Wickremesinghe helped to broker the IMF bailout and stabilize the economy, although the austerity measures and higher taxes that followed have made him deeply unpopular with voters. “Sri Lanka has enjoyed a steady, if unspectacular recovery from the 2022 crisis,” Gareth Leather, senior Asia economist at Capital Economics Ltd., wrote in a note. “However, this progress could be put at risk depending on the results of this weekend’s presidential election.” Observers and some opinion surveys suggest the election may go to a run-off for the first time since the system was introduced in 1982. Under Sri Lanka’s election rules, each voter casts three ballots in order of preference. A candidate needs more than 50% of first-preference votes to win. If no candidate reaches that mark, then voters’ second and third preferences are added to the count, and the person with the most votes is declared the winner. Polls close at 4 p.m. local time and counting begins immediately. A winner may be known by Sunday, although an uncertain result may cause delays. Wickremesinghe, 75, has been campaigning on his track record of bringing inflation down from 70% two years ago to low single digits now, and negotiating a debt restructuring with creditors like China and private bondholders. He says policy stability is needed to help bolster the recovery. “I’ve been upfront with them, I’ve not been promising them things I can’t do,” the president said in an interview in Colombo on Friday. “I said it’s going to be difficult before it gets better.” Premadasa, 57, is the main opposition leader who heads a political party that split from Wickremesinghe’s in 2020. A former minister of housing and health in previous governments, Premadasa draws much of his support from poorer Sri Lankans and the Tamil minority. He’s vowed to boost exports to spur growth and tackle corruption. Dissanayake, 55, leads the National People’s Power, a coalition of leftist political parties and groups backed by protesters who ousted then-leader Gotabaya Rajapaksa from power two years ago. Some opinion polls have put him ahead of his competitors in the election, and his rallies have been drawing significant crowds in recent weeks on pledges to fight corruption. Dissanayake has vowed to reopen negotiations with the IMF, and some in his party oppose the debt restructuring framework agreed with the IMF. Investors are bracing for turmoil in financial markets as the IMF loan program hangs in the balance. Sri Lanka will need to meet certain economic targets before the IMF approves the next tranche of funding, estimated at about $350 million. “There is a worry about negative repercussions if there is an effort to tinker or renegotiate either the current IMF program or the proposed agreement with debt holders,” said Navin Ratnayake, the head of research at Colombo-based John Keells. --With assistance from Asantha Sirimanne, Anup Roy, Sudhi Ranjan Sen and Dan Strumpf. Most Read from Bloomberg Businessweek ©2024 Bloomberg L.P.', 'date': '2024-09-21', 'time': '01:30:00.000', 'link': 'https://finance.yahoo.com/news/sri-lankans-vote-tight-race-013000137.html'}
2024-09-21 10:26:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2024-09-21 10:27:02 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "finance.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:27:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/california-governor-sign-law-protect-024557648.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:27:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news/california-governor-sign-law-protect-024557648.html> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:27:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/cancel-costco-membership-immediately-3-101510438.html> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:27:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/us-postal-not-hike-stamp-182738612.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:27:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news/us-postal-not-hike-stamp-182738612.html> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:27:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/sugar-biggest-jump-since-2008-120542033.html> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:27:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/sumitomo-hires-juan-toro-ceo-143000964.html> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:27:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:27:23 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 0, unchecked: 94, reanimated: 0, mean backoff time: 0s)
2024-09-21 10:27:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/why-social-media-companies-keep-183000571.html> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:27:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/three-mile-island-nuclear-reactor-to-restart-under-microsoft-deal-154812499.html> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:27:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:27:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/us-sec-intends-seek-sanctions-200024014.html> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:27:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/j-j-subsidiary-files-bankruptcy-193903276.html> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:27:39 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "finance.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:27:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/live/stock-market-today-dow-ekes-out-another-record-amid-winning-week-for-stocks-200133466.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:27:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news/live/stock-market-today-dow-ekes-out-another-record-amid-winning-week-for-stocks-200133466.html> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:27:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/robots.txt> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:27:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 4 pages/min), scraped 3 items (at 1 items/min)
2024-09-21 10:27:53 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 0, unchecked: 94, reanimated: 0, mean backoff time: 0s)
2024-09-21 10:28:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/robots.txt> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:28:23 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 0, unchecked: 94, reanimated: 0, mean backoff time: 0s)
2024-09-21 10:28:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2024-09-21 10:28:53 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 0, unchecked: 94, reanimated: 0, mean backoff time: 0s)
2024-09-21 10:29:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', '', 'packet length too long'), ('SSL routines', '', 'record layer failure')]>]
2024-09-21 10:29:18 [rotating_proxies.expire] DEBUG: Proxy <http://103.157.117.116:80> is DEAD
2024-09-21 10:29:18 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/robots.txt> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:29:23 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 1, unchecked: 93, reanimated: 0, mean backoff time: 172s)
2024-09-21 10:29:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/robots.txt> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:29:39 [rotating_proxies.expire] DEBUG: Proxy <http://157.66.37.12:8080> is DEAD
2024-09-21 10:29:39 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/robots.txt> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:29:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/robots.txt> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:29:43 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.94:8355> is DEAD
2024-09-21 10:29:43 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/robots.txt> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:29:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/robots.txt> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:29:46 [rotating_proxies.expire] DEBUG: Proxy <http://67.43.236.20:10145> is DEAD
2024-09-21 10:29:46 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/robots.txt> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:29:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/robots.txt> (failed 3 times): Could not open CONNECT tunnel with proxy 123.126.158.50:80 [{'status': 502, 'reason': b'Bad Gateway'}]
2024-09-21 10:29:47 [rotating_proxies.expire] DEBUG: Proxy <http://123.126.158.50:80> is DEAD
2024-09-21 10:29:47 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/robots.txt> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:29:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/robots.txt> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:29:51 [rotating_proxies.expire] DEBUG: Proxy <http://85.175.5.50:3128> is DEAD
2024-09-21 10:29:51 [rotating_proxies.middlewares] DEBUG: Gave up retrying <GET https://sports.yahoo.com/robots.txt> (failed 6 times with different proxies)
2024-09-21 10:29:51 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://sports.yahoo.com/robots.txt>: Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:29:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2024-09-21 10:29:53 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 6, unchecked: 88, reanimated: 0, mean backoff time: 222s)
2024-09-21 10:30:11 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://finance.yahoo.com/news/trump-media-nosedives-record-low-161159651.html. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2024-09-21 10:30:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/trump-media-nosedives-record-low-161159651.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: >]
2024-09-21 10:30:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/newsletters/yahoo-sports-am/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:30:23 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 6, unchecked: 88, reanimated: 0, mean backoff time: 222s)
2024-09-21 10:30:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2024-09-21 10:30:53 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 6, unchecked: 88, reanimated: 0, mean backoff time: 222s)
2024-09-21 10:31:23 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 6, unchecked: 88, reanimated: 0, mean backoff time: 222s)
2024-09-21 10:31:53 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2024-09-21 10:31:53 [rotating_proxies.middlewares] INFO: Proxies(good: 6, dead: 6, unchecked: 88, reanimated: 0, mean backoff time: 222s)
2024-09-21 10:32:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/> (failed 1 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/ took longer than 360 seconds..
2024-09-21 10:32:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/topic/stock-market-news/> (failed 1 times): User timeout caused connection failure: Getting https://finance.yahoo.com/topic/stock-market-news/ took longer than 360 seconds..
2024-09-21 10:32:12 [rotating_proxies.expire] DEBUG: Proxy <http://64.92.82.59:8080> is GOOD
2024-09-21 10:32:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://help.yahoo.com/robots.txt> (referer: None)
2024-09-21 10:32:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.yahoo.com/robots.txt> (failed 3 times): User timeout caused connection failure: Getting https://www.yahoo.com/robots.txt took longer than 360 seconds..
2024-09-21 10:32:12 [rotating_proxies.expire] DEBUG: Proxy <http://211.104.20.205:8080> is DEAD
2024-09-21 10:32:12 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://www.yahoo.com/robots.txt> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:32:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/existing-home-sales-fall-in-august-despite-lower-mortgage-rates-171246859.html> (failed 1 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/existing-home-sales-fall-in-august-despite-lower-mortgage-rates-171246859.html took longer than 360 seconds..
2024-09-21 10:32:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:32:23 [rotating_proxies.middlewares] INFO: Proxies(good: 7, dead: 6, unchecked: 86, reanimated: 1, mean backoff time: 227s)
2024-09-21 10:32:23 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:32:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.yahoo.com/robots.txt> (failed 3 times): Could not open CONNECT tunnel with proxy 47.88.31.196:8080 [{'status': 504, 'reason': b'Gateway Time-out'}]
2024-09-21 10:32:28 [rotating_proxies.expire] DEBUG: Proxy <http://47.88.31.196:8080> is DEAD
2024-09-21 10:32:28 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://www.yahoo.com/robots.txt> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:32:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.yahoo.com/robots.txt> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:32:31 [rotating_proxies.expire] DEBUG: Proxy <http://20.204.214.79:3129> is DEAD
2024-09-21 10:32:31 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://www.yahoo.com/robots.txt> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:32:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://help.yahoo.com/kb/sports-news> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:32:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/newsletters/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:32:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/college-football/news/> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:32:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/nhl/news/> (failed 1 times): Could not open CONNECT tunnel with proxy 145.40.97.148:10001 [{'status': 502, 'reason': b'Bad Gateway'}]
2024-09-21 10:32:52 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.yahoo.com/robots.txt> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:32:52 [rotating_proxies.expire] DEBUG: Proxy <http://190.61.90.117:8080> is DEAD
2024-09-21 10:32:52 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://www.yahoo.com/robots.txt> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:32:53 [rotating_proxies.expire] DEBUG: Proxy <http://192.9.237.224:3128> is GOOD
2024-09-21 10:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.yahoo.com/robots.txt> (referer: None)
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.yahoo.com/news/>
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.yahoo.com/news/us/>
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.yahoo.com/news/politics/>
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.yahoo.com/news/world/>
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.yahoo.com/news/health/>
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.yahoo.com/news/science/>
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.yahoo.com/news/tagged/360/>
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.yahoo.com/news/originals/>
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.robotstxt] DEBUG: Forbidden by robots.txt: <GET https://www.yahoo.com/news/weather/>
2024-09-21 10:32:53 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 2 pages/min), scraped 3 items (at 0 items/min)
2024-09-21 10:32:53 [rotating_proxies.middlewares] INFO: Proxies(good: 8, dead: 8, unchecked: 82, reanimated: 2, mean backoff time: 235s)
2024-09-21 10:32:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/fantasy/news/> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', '', 'packet length too long'), ('SSL routines', '', 'record layer failure')]>]
2024-09-21 10:32:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> from <GET https://sports.yahoo.com/newsletters/>
2024-09-21 10:32:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/nfl/news/> (failed 1 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:32:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/nba/news/> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:32:58 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "finance.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:32:58 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "sports.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:33:00 [rotating_proxies.expire] DEBUG: Proxy <http://47.251.87.74:9080> is GOOD
2024-09-21 10:33:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/existing-home-sales-fall-in-august-despite-lower-mortgage-rates-171246859.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news/existing-home-sales-fall-in-august-despite-lower-mortgage-rates-171246859.html> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:33:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sports.yahoo.com/mlb/news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sports.yahoo.com/mlb/news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:33:01 [rotating_proxies.expire] DEBUG: Proxy <http://187.157.243.254:8080> is GOOD
2024-09-21 10:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sports.yahoo.com/college-football/news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sports.yahoo.com/college-football/news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:33:02 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://sports.yahoo.com/nhl/news/. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2024-09-21 10:33:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/nhl/news/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: Chunked decoder in 'BODY' state, still expecting more data to get to 'FINISHED' state.>]
2024-09-21 10:33:02 [rotating_proxies.expire] DEBUG: Proxy <http://31.44.7.32:8080> is GOOD
2024-09-21 10:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:33:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/news/> (failed 1 times): Could not open CONNECT tunnel with proxy 147.78.1.154:8080 [{'status': 503, 'reason': b'Service Unavailable'}]
2024-09-21 10:33:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news> (failed 1 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news took longer than 360 seconds..
2024-09-21 10:33:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/nfl/news/> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:33:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/trump-media-nosedives-record-low-161159651.html> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:33:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:33:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', '', 'packet length too long'), ('SSL routines', '', 'record layer failure')]>]
2024-09-21 10:33:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/why-social-media-companies-keep-183000571.html> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:33:10 [rotating_proxies.expire] DEBUG: Proxy <http://43.134.68.153:3128> is GOOD
2024-09-21 10:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/three-mile-island-nuclear-reactor-to-restart-under-microsoft-deal-154812499.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/three-mile-island-nuclear-reactor-to-restart-under-microsoft-deal-154812499.html>
{'title': 'Three Mile Island nuclear reactor to restart under Microsoft deal', 'content': 'A Three Mile Island nuclear reactor is set to come back online after more than five years under a new deal between Microsoft ( ) and Constellation Energy ( ). The announcement on Friday boosted shares of the Baltimore-based energy provider by more than 20 per cent during the trading session. Pennsylvania’s Three Mile Island is notorious for one of the worst commercial nuclear accidents in U.S. history, following a partial meltdown of the Unit 2 reactor in 1979. The deal between Microsoft and Constellation would restart the neighbouring but fully independent Unit 1 reactor, which was shut down for economic reasons in 2019. In a news release on Friday, Constellation says the power purchase deal with the tech giant is its largest ever, aiming to provide upwards of 800 megawatts to the grid when a planned energy centre comes online in 2028. For Microsoft, the agreement secures emissions-free power to help match demand in the region from its increasingly power-hungry data centres, as the company pushes harder into artificial intelligence. “Powering industries critical to our nation’s global economic and technological competitiveness, including data centres, requires an abundance of energy that is carbon-free and reliable every hour of every day, and nuclear plants are the only energy sources that can consistently deliver on that promise,” Constellation president and CEO Joe Dominguez stated in a news release. “Before it was prematurely shuttered due to poor economics, this plant was among the safest and most reliable nuclear plants on the grid, and we look forward to bringing it back.” Constellation says this requires U.S. Nuclear Regulatory Commission approval, following a comprehensive safety and environmental review, as well as permits from relevant state and local agencies. "This agreement is a major milestone in Microsoft\'s efforts to help decarbonize the grid in support of our commitment to become carbon negative,” Bobby Hollis, Microsoft’s vice-president of energy, stated in Friday’s news release. Microsoft, along with rivals Alphabet ( )( ) and Amazon ( ), are among the top corporate buyers of renewable energy from wind and solar. In May,   ( ) for more than 10.5 gigawatts of renewable energy capacity in the U.S. and Europe starting in 2026. According to BloombergNEF, this was the largest single announcement for a corporate clean-power purchase agreement announced at the time. Expectations of   have sent uranium prices to their highest levels since the early 2000s, as the mining industry forecasts a shortfall of supply. Meanwhile, companies including Enbridge ( )( ) and TC Energy ( )( ) have presented  . Nasdaq-listed Constellation Energy shares closed 22.29 per cent higher at $254.98 on Friday. Microsoft’s stock slipped 0.78 per cent to $435.27. .', 'date': '2024-09-20', 'time': '20:12:55.000', 'link': 'https://finance.yahoo.com/news/three-mile-island-nuclear-reactor-to-restart-under-microsoft-deal-154812499.html'}
2024-09-21 10:33:12 [rotating_proxies.expire] DEBUG: Proxy <http://160.86.242.23:8080> is GOOD
2024-09-21 10:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/sugar-biggest-jump-since-2008-120542033.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/sugar-biggest-jump-since-2008-120542033.html>
{'title': 'Sugar’s Biggest Jump Since 2008 Is a Fresh Threat to Food Prices', 'content': '(Bloomberg) -- Sugar prices are surging as fires and drought slam fields in top grower Brazil, threatening higher costs for sweets and desserts. Most Read from Bloomberg Raw sugar futures headed for their biggest weekly gain in 16 years, as traders digested the extent of crop damage from the blazes and a blistering heat wave in the nation. Sao Paulo state — part of Brazil’s main Center-South growing region — has faced a record number of fires this August due to a lack of moisture. That damaged cane roots, and may force producers to replant or face a smaller harvest in the upcoming season. It also followed a long dry spell since last October, which curbed yields. While shifts in farmgate prices take time to feed through to the grocery store, sugar’s latest surge puts the sweetener on track for a sixth straight annual gain, keeping pressure on foodmakers. Trader Wilmar International Ltd. lowered its forecast for sugar output in the Center-South, citing a series of “unusual and persistent weather events.” In a post on X, Wilmar said fires last month impacted as much as 450,000 hectares (1.1 million acres) of sugar cane. Mills in Brazil are expected to halt cane processing as early as the end of October, Rabobank analyst Andy Duff said in a report. That’s as poor crop yields will likely force them to a premature end of the season. “There is a prospect of a tightening in global sugar availability for export in the first quarter of 2025,” Duff said. The jump in sugar coincides with a surge the price of other crops like coffee and cocoa, putting particular strain on the beverage and dessert aisles. The weather-fueled price increases come as consumer goods companies already face challenges trying to coax shoppers back to some premium foods brands after a period of high inflation and belt-tightening. The challenging environment has prompted leadership changes in the food industry. Nestle SA Chief Executive Officer Mark Schneider unexpectedly left the Swiss producer of KitKat and Nescafé last month. Laxman Narasimhan also recently lost his job as CEO of Starbucks Corp. after less than two years. The most-active raw sugar future rose as much as 3.8% in New York on Friday. It’s currently on track for a gain of almost 16% this week, which would be the biggest weekly advance since June 2008. Brazil is set to remain mostly dry during the next 6 to 10 days, although “light showers will be possible” in the southern portions of the Center-South on Friday and Saturday, according to forecaster Maxar Technologies Inc. An improvement in weather conditions in October is “unlikely to benefit this current crop, maybe only the next crop,” according to Wilmar. --With assistance from Dayanne Sousa. Most Read from Bloomberg Businessweek ©2024 Bloomberg L.P.', 'date': '2024-09-20', 'time': '15:02:42.000', 'link': 'https://finance.yahoo.com/news/sugar-biggest-jump-since-2008-120542033.html'}
2024-09-21 10:33:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://help.yahoo.com/kb/sports-news> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:16 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "finance.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:33:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> (failed 1 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html took longer than 360 seconds..
2024-09-21 10:33:18 [rotating_proxies.expire] DEBUG: Proxy <http://8.148.22.214:9080> is GOOD
2024-09-21 10:33:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/cancel-costco-membership-immediately-3-101510438.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news/cancel-costco-membership-immediately-3-101510438.html> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:33:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/nba/news/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', '', 'packet length too long'), ('SSL routines', '', 'record layer failure')]>]
2024-09-21 10:33:20 [rotating_proxies.expire] DEBUG: Proxy <http://35.225.16.82:2387> is GOOD
2024-09-21 10:33:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/j-j-subsidiary-files-bankruptcy-193903276.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/j-j-subsidiary-files-bankruptcy-193903276.html>
{'title': 'J&J subsidiary files for bankruptcy to advance $8 billion talc settlement', 'content': "A Johnson & Johnson subsidiary filed for bankruptcy for a third time on Friday as the healthcare giant seeks to advance an approximately $8 billion proposed settlement that would end tens of thousands of lawsuits alleging that the company's baby powder and other talc products caused cancer. (Reporting by Dietrich Knauth and Bhanvi Satija in Bengaluru; Editing by Leigh Jones, Will Dunham and Sandra Maler)", 'date': '2024-09-20', 'time': '19:39:03.000', 'link': 'https://finance.yahoo.com/news/j-j-subsidiary-files-bankruptcy-193903276.html'}
2024-09-21 10:33:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/newsletters/yahoo-sports-am/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:23 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 8, unchecked: 75, reanimated: 2, mean backoff time: 235s)
2024-09-21 10:33:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/us-sec-intends-seek-sanctions-200024014.html> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/news/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://news.yahoo.com/originals/> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', '', 'packet length too long'), ('SSL routines', '', 'record layer failure')]>]
2024-09-21 10:33:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/millennial-fire-couple-shares-moving-180302476.html> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:33:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/sumitomo-hires-juan-toro-ceo-143000964.html> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:35 [rotating_proxies.expire] DEBUG: Proxy <http://58.240.211.250:7890> is DEAD
2024-09-21 10:33:35 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/brazil-trims-2024-spending-freeze-002356049.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:33:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/mark-zuckerberg-declares-meta-opposite-090000043.html> (failed 1 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/mark-zuckerberg-declares-meta-opposite-090000043.html took longer than 360 seconds..
2024-09-21 10:33:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html> (failed 2 times): Could not open CONNECT tunnel with proxy 43.134.32.184:3128 [{'status': 500, 'reason': b'Internal Server Error'}]
2024-09-21 10:33:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/mark-zuckerberg-declares-meta-opposite-090000043.html> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:33:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/most-people-expect-retire-67-193051193.html> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:33:43 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:33:47 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "finance.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:33:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:48 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:33:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/topic/premium-news> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:48 [rotating_proxies.expire] DEBUG: Proxy <http://212.112.113.182:3128> is GOOD
2024-09-21 10:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/topic/economic-news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/topic/economic-news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:33:49 [rotating_proxies.expire] DEBUG: Proxy <http://8.220.204.215:8008> is GOOD
2024-09-21 10:33:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/topic/latest-news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:33:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/topic/latest-news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:33:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=LcjwSu8&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fmost-people-expect-retire-67-193051193.html> from <GET https://finance.yahoo.com/news/most-people-expect-retire-67-193051193.html>
2024-09-21 10:33:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/own-home-hope-buy-one-090020148.html> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/topic/premium-news> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:33:51 [rotating_proxies.expire] DEBUG: Proxy <http://67.43.228.250:26991> is DEAD
2024-09-21 10:33:51 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/topic/premium-news> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:33:53 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 10 pages/min), scraped 6 items (at 3 items/min)
2024-09-21 10:33:53 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 8, unchecked: 71, reanimated: 4, mean backoff time: 224s)
2024-09-21 10:33:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/own-home-hope-buy-one-090020148.html> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2024-09-21 10:33:55 [rotating_proxies.expire] DEBUG: Proxy <http://24.57.147.22:8080> is DEAD
2024-09-21 10:33:55 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/own-home-hope-buy-one-090020148.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:33:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/brazil-trims-2024-spending-freeze-002356049.html> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:33:58 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:33:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/own-home-hope-buy-one-090020148.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:33:59 [rotating_proxies.expire] DEBUG: Proxy <http://209.126.13.43:62442> is DEAD
2024-09-21 10:33:59 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/own-home-hope-buy-one-090020148.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:34:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://news.yahoo.com/newsletters/> (failed 2 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:34:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/own-home-hope-buy-one-090020148.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:34:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/own-home-hope-buy-one-090020148.html>
{'title': 'If you own a home or hope to buy one soon, what does the Fed’s interest rate cut mean for you?', 'content': 'On Wednesday, the Federal Reserve cut interest rates for the first time since the early days of the COVID-19 pandemic, slashing its benchmark rate   and signaling more rate cuts by the end of the year. The housing market is one of the most interest-rate-sensitive sectors of the US economy, and over the past few years, elevated mortgage rates, along with sky-high housing prices, have contributed to a lack of home affordability. The supply of homes for sale hasn’t kept up with demand as homeowners who locked in ultra-low pandemic-era mortgage rates were less willing to sell their homes in a higher mortgage rate environment. Some experts believe falling rates could entice more homeowners to put their homes up for sale. In the past few months, rates have steadily fallen in anticipation of interest rate cuts. The standard 30-year fixed-rate mortgage averaged 6.09% in the week ended September 19, according to Freddie Mac, down significantly from 7.79% last fall. Does the Fed’s recent interest rate cut and the potential for more rate cuts in the future change your outlook as a homeowner or a potential homebuyer? If so, we would love to hear from you. Please share your thoughts with us in the form below. For more CNN news and newsletters create an account at ', 'date': '2024-09-20', 'time': '09:00:20.000', 'link': 'https://finance.yahoo.com/news/own-home-hope-buy-one-090020148.html'}
2024-09-21 10:34:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=Ec4Cv5c&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fbrazil-trims-2024-spending-freeze-002356049.html> from <GET https://finance.yahoo.com/news/brazil-trims-2024-spending-freeze-002356049.html>
2024-09-21 10:34:03 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:34:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:34:04 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.174:13093> is DEAD
2024-09-21 10:34:04 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:34:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:34:09 [rotating_proxies.expire] DEBUG: Proxy <http://103.93.94.121:80> is DEAD
2024-09-21 10:34:09 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:34:11 [rotating_proxies.expire] DEBUG: Proxy <http://210.61.207.92:80> is GOOD
2024-09-21 10:34:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/topic/premium-news> (referer: https://finance.yahoo.com/)
2024-09-21 10:34:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/topic/premium-news> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:34:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:34:12 [rotating_proxies.expire] DEBUG: Proxy <http://67.43.228.252:10579> is DEAD
2024-09-21 10:34:12 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:34:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:34:13 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://210.61.207.92:80>
2024-09-21 10:34:13 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:34:18 [rotating_proxies.expire] DEBUG: Proxy <http://103.157.117.116:80> is GOOD
2024-09-21 10:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/mark-zuckerberg-declares-meta-opposite-090000043.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:34:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/mark-zuckerberg-declares-meta-opposite-090000043.html>
{'title': 'Mark Zuckerberg declares Meta ‘the opposite’ of Apple in comments reigniting Tim Cook feud', 'content': 'If Mark Zuckerberg’s  —complete with shaggy hair and chunky gold chain—is any indication, he’s much different from the straightlaced, crew-cutted   ( ) CEO Tim Cook. It’s no wonder, then, that the business philosophies of Zuckerberg’s Meta ( ) and Apple are as different as their two leaders. Zuckerberg has been eager to point out those differences and prod at a decades-long feud between the two tech giants and their chief executives. While Meta has prioritized acting fast and engaging users, such as through its   of its Llama AI model, Zuckerberg said in the   released Tuesday, Apple prefers maintaining a   of polished, exclusive products. "I think in a lot of ways we\'re like the opposite of Apple," he said. "Clearly, their stuff has worked really well too. They take this approach that\'s like, \'We\'re going to take a long time, we\'re going to polish it, we\'re going to put it out,\' and maybe for the stuff that they\'re doing that works, maybe that just fits with their culture." Since Tim Cook took the helm of the tech behemoth, Apple has   on being the best, rather than the first. For the most part, it’s worked out for the company, demonstrated by its superlative of the  . Apple has long tended to its walled garden of in-house products, which has resulted in a uniform line of apps and accessories bespoke to its tech—and a whopping   from the Department of Justice. But Zuckerberg touted Meta’s own spaghetti-at-the-wall approach to its products, which he believes has elicited helpful critiques and enabled the company to grow in spite of its failures. "You want to really have a culture that values shipping and getting things out and getting feedback more than needing always to get great positive accolades from people when you put stuff out," he said. There’s certainly been no shortage of feedback toward Meta, exemplified by social media platform Thread’s meteoric rise to 100 million users, only for the number of accounts to atrophy  . Its flagship Metaverse was a  , but that still hasn’t stopped Zuckerberg from adding $58 billion to his net worth this year. Apple’s perfectionism has been at its own expense, Zuckerberg said, arguing the company prioritizes praise above constructive feedback from users. "If you want to wait until you get praised all the time,” he said, “you\'re missing a bunch of the time when you could\'ve learned a bunch of useful stuff and then incorporated that into the next version you\'re going to ship.” Apple and Meta did not immediately respond to  ’s requests for comment. Zuckerberg’s commentary on Apple’s ways of doing business is not the first time he’s shared his thoughts on Cook’s company. For over a decade, he and Cook have differed on their philosophies not only on how to roll out products, but on the future of the internet more broadly. Earlier this month Meta and Apple’s feud reached a fever pitch after Meta urged   of social media platforms, suggesting Apple and   set age restrictions and requirements for parental consent. But Apple  , arguing the onus for restrictions should be placed on the platform themselves. Tensions between the two companies have been tightening  , when Cook suggested   made its money through the collection of personal data. The following year, Apple unveiled its motto, “Privacy is a fundamental human right.” Cook also lambasted Facebook as a hotbed for Russian misinformation used to mislead American voters ahead of the 2016 election. Zuckerberg seems keen on fanning the flames of the tech rivalry today, calling Apple Meta’s “primary competitor” on Tuesday’s podcast. Cook historically has not agreed. "Oh, I think that we compete in some things," Cook  . "But no, if I may ask who our biggest competitors are, they would not be listed. We\'re not in the social networking business." This story was originally featured on ', 'date': '2024-09-20', 'time': '21:33:49.000', 'link': 'https://finance.yahoo.com/news/mark-zuckerberg-declares-meta-opposite-090000043.html'}
2024-09-21 10:34:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://news.yahoo.com/newsletters/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:34:21 [rotating_proxies.expire] DEBUG: Proxy <http://18.228.173.216:3128> is DEAD
2024-09-21 10:34:21 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://news.yahoo.com/newsletters/> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:34:22 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "finance.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:34:23 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 12, unchecked: 64, reanimated: 6, mean backoff time: 214s)
2024-09-21 10:34:24 [rotating_proxies.expire] DEBUG: Proxy <http://154.205.152.96:7071> is GOOD
2024-09-21 10:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/sumitomo-hires-juan-toro-ceo-143000964.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:34:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news/sumitomo-hires-juan-toro-ceo-143000964.html> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:34:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://news.yahoo.com/newsletters/> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:34:24 [rotating_proxies.expire] DEBUG: Proxy <http://20.219.176.57:3129> is DEAD
2024-09-21 10:34:24 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://news.yahoo.com/newsletters/> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:34:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> (failed 3 times): Could not open CONNECT tunnel with proxy 43.134.32.184:3128 [{'status': 500, 'reason': b'Internal Server Error'}]
2024-09-21 10:34:25 [rotating_proxies.expire] DEBUG: Proxy <http://43.134.32.184:3128> is DEAD
2024-09-21 10:34:25 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:34:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/millennial-fire-couple-shares-moving-180302476.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:34:27 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.93:13931> is DEAD
2024-09-21 10:34:27 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/millennial-fire-couple-shares-moving-180302476.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:34:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://news.yahoo.com/newsletters/> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:34:27 [rotating_proxies.expire] DEBUG: Proxy <http://67.43.227.226:30373> is DEAD
2024-09-21 10:34:27 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://news.yahoo.com/newsletters/> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:34:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://news.yahoo.com/newsletters/> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:34:29 [rotating_proxies.expire] DEBUG: Proxy <http://117.2.192.50:5006> is DEAD
2024-09-21 10:34:29 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://news.yahoo.com/newsletters/> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:34:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:34:33 [rotating_proxies.expire] DEBUG: Proxy <http://43.134.32.184:3128> is DEAD
2024-09-21 10:34:33 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:34:34 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "news.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:34:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://news.yahoo.com/newsletters/> (referer: https://finance.yahoo.com/)
2024-09-21 10:34:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://news.yahoo.com/newsletters/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:34:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/millennial-fire-couple-shares-moving-180302476.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:34:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/millennial-fire-couple-shares-moving-180302476.html>
{'title': 'A millennial FIRE couple shares how moving abroad and living on a $50k income helped them quadruple their net worth to $700k in 6 years', 'content': 'A millennial couple grew their net worth to over $700,000 from $150,000 in 2018. Living abroad and only spending one of their incomes, which is $50,000, helped boost their finances. Brian Davis shared why his goal isn\'t\xa0 \xa0but to pursue his dream work. About two decades ago, before he\'d ever heard of the  , Brian Davis decided to pursue financial independence and an early retirement. He began investing his savings in  , thinking that if he owned enough of them, he\'d eventually be able to live off the rental income alone, the 43-year-old told Business Insider via email. But this didn\'t go according to plan. He hated being a  , and some of the investments proved to be less profitable than he\'d expected. The idea of retiring ahead of schedule seemed like it could be out of reach, so he decided to explore other options. Today, he runs a digital real estate investing platform. However, in the years since, a lot has changed for Davis — both from a financial and philosophical perspective. For one, he\'s grown his net worth to more than $700,000 as of May from roughly $150,000 in 2018, according to documents viewed by BI. Davis and his wife have aimed to live entirely off of his wife\'s roughly $50,000 a year school counselor salary while saving and investing all of his income, which comes primarily from a real estate   he cofounded in 2016 — he said their annual household income is around $150,000. This saving strategy has been key to boosting their finances. Davis\'s financial goals have also evolved. After learning more about the   — a financial lifestyle aimed at saving enough to become financially independent and retire before the traditional retirement age — Davis said he discovered that most people who managed to retire early eventually got bored of "sipping margaritas on the beach" and returned to work in some form. Rather than early retirement, Davis said his current goal is to live his ideal life, and he thinks remaining in the workforce can help him accomplish this. "I have no plans to retire, but I do hope to reach financial independence within the next five years," he said. "The less you worry about money, the more your work opens up to be fun, creative, and without limits on opportunities." While many Americans are having trouble  , some are putting themselves in a position to   ahead of schedule through various savings and investment strategies. However, not all of these people are aiming for an early retirement. Some people, like Davis, want to continue working as they pursue financial security. But not just any kind of work: They want to\xa0 \xa0that they enjoy or find fulfilling. Davis shared how he\'s grown his net worth — and why he thinks finding one\'s dream work can help them live their ideal life. Davis and his family, including his wife Katie and their daughter, have a huge financial advantage: They don\'t pay for housing. This is among the perks of Katie\'s job: She works as a school counselor at international schools around the world. Davis said they first moved abroad in 2015, spending four years in Abu Dhabi and four years in Brazil before moving to Lima,   about a year ago. Davis said it\'s not unusual for international schools to provide free housing for faculty and staff. In addition to saving money on housing, they\'ve been able to take advantage of the "lower cost of living overseas," including cheaper food and  . Davis said this was among the main reasons they decided to venture abroad. "You can buy beef and pork in South America for a quarter of the cost in the US," he said. Davis said another big way he\'s been able to save money is by   — he said he hasn\'t owned a car in five years. "People don\'t realize how much more cars cost than just the monthly payment," he said. "Without a car, we don\'t have to pay for car insurance, repairs and maintenance, gas, parking." The family\'s reduced living expenses have enabled them to live entirely on Katie\'s salary. However, Davis said that they don\'t expect to have these financial perks forever, so they\'re trying to take advantage of them now. "At some point, we know we\'ll have to move back to the US for family reasons," Davis said. "So we\'re trying to build our net worth and passive income streams as quickly as possible before we do." When Davis learned that many early retirees return to work in some form, he said this revelation was in some ways disappointing. However, he\'s since changed his tune. For example, if a person retires at age 60 — rather than age 50 — then it would be much easier for them to hit their retirement savings goal. "It means that you don\'t need nearly as much money as you thought you did," Davis said. "If you\'re going to keep doing some kind of work on your own terms, you\'ll keep earning active income." However, that extra decade of work might not be satisfactory for everyone. That\'s why Davis thinks the key is finding one\'s dream work. Davis said if someone is doing work they enjoy, then they likely won\'t be so desperate to give up work and retire. And even if this means transitioning to work that\'s lower-paying than one\'s old job, Davis said this is where the   well-discussed in the FIRE community can come in handy: They can help bridge the gap between one\'s desired and actual income. "You just need enough money to cover any shortfall between what you want to spend and what your dream work pays," he said. "In other words, you can start living your ideal life now, or very soon, without being financially independent." To be sure, finding a job — forget about one\'s dream job — is easier said than done in today\'s economy. Many Americans are having a   as companies pull back on hiring. For Davis, his business is one component of his dream work. He said he gets all the benefits of real estate investment without the headaches of being a landlord. "I don\'t consider myself financially independent, but I\'m living the same life that I would be if I were," he said. "I get to do work I love, on my own schedule, from anywhere in the world." His top advice for people is to envision their ideal lifestyle and determine what type of work and income level they need to make it a reality. "Once you reframe FIRE in those terms, it gets both easier and more fulfilling, rather than just dreaming about sitting on a beach as a bum for the rest of your life," he said. Read the original article on ', 'date': '2024-09-20', 'time': '18:03:02.000', 'link': 'https://finance.yahoo.com/news/millennial-fire-couple-shares-moving-180302476.html'}
2024-09-21 10:34:45 [rotating_proxies.expire] DEBUG: Proxy <http://103.4.167.15:8080> is GOOD
2024-09-21 10:34:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sports.yahoo.com/news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:34:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sports.yahoo.com/news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:34:49 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "finance.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:34:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/us-sec-intends-seek-sanctions-200024014.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:34:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news/us-sec-intends-seek-sanctions-200024014.html> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:34:53 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 8 pages/min), scraped 9 items (at 3 items/min)
2024-09-21 10:34:53 [rotating_proxies.middlewares] INFO: Proxies(good: 20, dead: 17, unchecked: 57, reanimated: 6, mean backoff time: 210s)
2024-09-21 10:34:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://news.yahoo.com/originals/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:34:56 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://103.4.167.15:8080>
2024-09-21 10:34:56 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://news.yahoo.com/originals/> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:35:01 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "news.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sports.yahoo.com/newsletters/yahoo-sports-am/> (referer: https://finance.yahoo.com/)
2024-09-21 10:35:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sports.yahoo.com/newsletters/yahoo-sports-am/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://news.yahoo.com/originals/> (referer: https://finance.yahoo.com/)
2024-09-21 10:35:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://news.yahoo.com/originals/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:35:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nba/news/> (failed 3 times): Could not open CONNECT tunnel with proxy 43.134.33.254:3128 [{'status': 502, 'reason': b'Bad Gateway'}]
2024-09-21 10:35:03 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://43.134.33.254:3128>
2024-09-21 10:35:03 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/nba/news/> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:35:10 [rotating_proxies.expire] DEBUG: Proxy <http://85.175.5.50:3128> is GOOD
2024-09-21 10:35:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sports.yahoo.com/nba/news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:35:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sports.yahoo.com/nba/news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:35:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://help.yahoo.com/kb/sports-news> (failed 3 times): Could not open CONNECT tunnel with proxy 43.134.229.98:3128 [{'status': 500, 'reason': b'Internal Server Error'}]
2024-09-21 10:35:15 [rotating_proxies.expire] DEBUG: Proxy <http://43.134.229.98:3128> is DEAD
2024-09-21 10:35:15 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://help.yahoo.com/kb/sports-news> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:35:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://help.yahoo.com/kb/sports-news> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:35:18 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.90:1365> is DEAD
2024-09-21 10:35:18 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://help.yahoo.com/kb/sports-news> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:35:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://help.yahoo.com/kb/sports-news> (failed 3 times): Could not open CONNECT tunnel with proxy 145.40.97.148:10001 [{'status': 502, 'reason': b'Bad Gateway'}]
2024-09-21 10:35:19 [rotating_proxies.expire] DEBUG: Proxy <http://145.40.97.148:10001> is DEAD
2024-09-21 10:35:19 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://help.yahoo.com/kb/sports-news> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:35:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://help.yahoo.com/kb/sports-news> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:35:22 [rotating_proxies.expire] DEBUG: Proxy <http://67.43.236.20:10145> is DEAD
2024-09-21 10:35:22 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://help.yahoo.com/kb/sports-news> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:35:23 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 23, unchecked: 54, reanimated: 4, mean backoff time: 206s)
2024-09-21 10:35:38 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:35:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://help.yahoo.com/kb/sports-news> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:35:43 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://35.225.16.82:2387>
2024-09-21 10:35:43 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://help.yahoo.com/kb/sports-news> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:35:49 [rotating_proxies.expire] DEBUG: Proxy <http://180.88.111.187:3128> is DEAD
2024-09-21 10:35:49 [rotating_proxies.middlewares] DEBUG: Gave up retrying <GET https://help.yahoo.com/kb/sports-news> (failed 6 times with different proxies)
2024-09-21 10:35:49 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://help.yahoo.com/kb/sports-news> (referer: https://finance.yahoo.com/)
2024-09-21 10:35:49 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/why-social-media-companies-keep-183000571.html> (failed 3 times): Could not open CONNECT tunnel with proxy 74.48.105.68:3128 [{'status': 502, 'reason': b'Bad Gateway'}]
2024-09-21 10:35:49 [rotating_proxies.expire] DEBUG: Proxy <http://74.48.105.68:3128> is DEAD
2024-09-21 10:35:49 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/why-social-media-companies-keep-183000571.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:35:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=YoASOF0&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fwhy-social-media-companies-keep-183000571.html> from <GET https://finance.yahoo.com/news/why-social-media-companies-keep-183000571.html>
2024-09-21 10:35:53 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 4 pages/min), scraped 9 items (at 0 items/min)
2024-09-21 10:35:53 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 24, unchecked: 52, reanimated: 6, mean backoff time: 213s)
2024-09-21 10:36:08 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:36:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:36:23 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 22, unchecked: 52, reanimated: 8, mean backoff time: 218s)
2024-09-21 10:36:23 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:36:33 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:36:43 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:36:53 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 0 pages/min), scraped 9 items (at 0 items/min)
2024-09-21 10:36:53 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 18, unchecked: 52, reanimated: 12, mean backoff time: 230s)
2024-09-21 10:37:13 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:37:23 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 16, unchecked: 52, reanimated: 14, mean backoff time: 236s)
2024-09-21 10:37:33 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:37:38 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:37:53 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 0 pages/min), scraped 9 items (at 0 items/min)
2024-09-21 10:37:53 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 13, unchecked: 52, reanimated: 17, mean backoff time: 244s)
2024-09-21 10:37:53 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:37:58 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:38:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:38:18 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:38:23 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 9, unchecked: 52, reanimated: 21, mean backoff time: 267s)
2024-09-21 10:38:23 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:38:28 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:38:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/soccer/news/> (failed 1 times): User timeout caused connection failure: Getting https://sports.yahoo.com/soccer/news/ took longer than 360 seconds..
2024-09-21 10:38:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/soccer/news/> (failed 2 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:38:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/topic/stock-market-news/> (failed 2 times): User timeout caused connection failure: Getting https://finance.yahoo.com/topic/stock-market-news/ took longer than 360 seconds..
2024-09-21 10:38:53 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 0 pages/min), scraped 9 items (at 0 items/min)
2024-09-21 10:38:53 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 7, unchecked: 52, reanimated: 23, mean backoff time: 272s)
2024-09-21 10:38:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://sports.yahoo.com/fantasy/news/> (failed 2 times): User timeout caused connection failure: Getting https://sports.yahoo.com/fantasy/news/ took longer than 360 seconds..
2024-09-21 10:38:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://guce.yahoo.com/robots.txt> (failed 1 times): User timeout caused connection failure: Getting https://guce.yahoo.com/robots.txt took longer than 360 seconds..
2024-09-21 10:38:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=FvpeiL8&done=https%3A%2F%2Ffinance.yahoo.com%2Ftopic%2Fstock-market-news%2F> from <GET https://finance.yahoo.com/topic/stock-market-news/>
2024-09-21 10:38:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/soccer/news/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:38:57 [rotating_proxies.expire] DEBUG: Proxy <http://27.96.131.193:80> is DEAD
2024-09-21 10:38:57 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/soccer/news/> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:38:58 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:39:03 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:39:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> (failed 2 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html took longer than 360 seconds..
2024-09-21 10:39:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/fantasy/news/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:39:14 [rotating_proxies.expire] DEBUG: Proxy <http://103.93.94.121:80> is DEAD
2024-09-21 10:39:14 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/fantasy/news/> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:39:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> (failed 2 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html took longer than 360 seconds..
2024-09-21 10:39:19 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "sports.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:39:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/warren-buffett-could-bought-379-090600668.html> (failed 2 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/warren-buffett-could-bought-379-090600668.html took longer than 360 seconds..
2024-09-21 10:39:20 [rotating_proxies.expire] DEBUG: Proxy <http://8.211.195.139:8443> is GOOD
2024-09-21 10:39:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sports.yahoo.com/fantasy/news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:39:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sports.yahoo.com/fantasy/news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:39:23 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 6, unchecked: 50, reanimated: 25, mean backoff time: 296s)
2024-09-21 10:39:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> (failed 2 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html took longer than 360 seconds..
2024-09-21 10:39:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', '', 'packet length too long'), ('SSL routines', '', 'record layer failure')]>]
2024-09-21 10:39:29 [rotating_proxies.expire] DEBUG: Proxy <http://149.129.255.179:8443> is DEAD
2024-09-21 10:39:29 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:39:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=JqB8EnY&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fwarren-buffett-could-bought-379-090600668.html> from <GET https://finance.yahoo.com/news/warren-buffett-could-bought-379-090600668.html>
2024-09-21 10:39:43 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:39:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:39:50 [rotating_proxies.expire] DEBUG: Proxy <http://156.200.116.78:1981> is DEAD
2024-09-21 10:39:50 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:39:53 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 1 pages/min), scraped 9 items (at 0 items/min)
2024-09-21 10:39:53 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 7, unchecked: 48, reanimated: 26, mean backoff time: 265s)
2024-09-21 10:40:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html took longer than 360 seconds..
2024-09-21 10:40:04 [rotating_proxies.expire] DEBUG: Proxy <http://47.243.92.199:3128> is DEAD
2024-09-21 10:40:04 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:40:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:40:07 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.92:5635> is DEAD
2024-09-21 10:40:07 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:40:08 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:40:12 [rotating_proxies.expire] DEBUG: Proxy <http://147.78.1.154:8080> is GOOD
2024-09-21 10:40:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:40:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html>
{'title': 'X names Brazil legal representative, its lawyers say', 'content': 'SAO PAULO (Reuters) - Elon Musk-owned social media platform X has named a legal representative in Brazil, the firm\'s lawyers said on Friday, in a move that would address one of the demands imposed by Brazil\'s top court to allow the company to operate in the country. Andre Zonaro and Sergio Rosenthal, who were recently appointed as X\'s lawyers in Brazil, told Reuters that colleague Rachel de Oliveira Conceicao was chosen as the firm\'s legal representative. In late August, Brazil\'s top court ordered mobile and internet service providers to block X in the nation, and users were cut off within hours. The shutdown followed a months-long dispute between Musk and Brazilian Justice Alexandre de Moraes over X\'s non-compliance with court orders demanding the platform take action against the spread of hate speech. Courts have previously blocked accounts implicated in probes of allegedly spreading misinformation and hate, which Musk has denounced as censorship, and had also ordered X to name a local legal representative as required by Brazilian law, after the firm closed its offices in Brazil in mid-August. On Thursday, the lawyers representing X in Brazil said the firm would present a legal representative to the local Supreme Court "very soon." They also said the firm was starting to comply with the orders on removing content, which is another demand from the top court. (Reporting by Andre Romani; Editing by Kylie Madry)', 'date': '2024-09-21', 'time': '00:36:38.000', 'link': 'https://finance.yahoo.com/news/x-names-brazil-legal-representative-003638875.html'}
2024-09-21 10:40:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:40:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:40:15 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.94:8355> is DEAD
2024-09-21 10:40:15 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:40:23 [rotating_proxies.middlewares] INFO: Proxies(good: 20, dead: 8, unchecked: 45, reanimated: 27, mean backoff time: 215s)
2024-09-21 10:40:25 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html took longer than 360 seconds..
2024-09-21 10:40:25 [rotating_proxies.expire] DEBUG: Proxy <http://4.234.78.115:8080> is DEAD
2024-09-21 10:40:25 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:40:28 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:40:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html took longer than 360 seconds..
2024-09-21 10:40:33 [rotating_proxies.expire] DEBUG: Proxy <http://154.118.229.142:3128> is DEAD
2024-09-21 10:40:33 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:40:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:40:36 [rotating_proxies.expire] DEBUG: Proxy <http://103.4.167.15:8080> is DEAD
2024-09-21 10:40:36 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:40:38 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:40:46 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:40:46 [rotating_proxies.expire] DEBUG: Proxy <http://157.66.37.12:8080> is DEAD
2024-09-21 10:40:46 [rotating_proxies.middlewares] DEBUG: Gave up retrying <GET https://finance.yahoo.com/news/theres-12-correction-looming-stock-013530520.html> (failed 6 times with different proxies)
2024-09-21 10:40:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/trump-media-nosedives-record-low-161159651.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:40:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/trump-media-nosedives-record-low-161159651.html>
{'title': 'Trump Media nosedives to record low on the first day Trump and other insiders can sell their shares', 'content': 'Trump Media stock plummeted Friday after company insiders, including former president Donald Trump, got the green light to begin selling shares. Shares for the owner of Trump’s Truth Social fell as much as 8% to $13.50 on Friday morning before a slight recovery. Shares were trading down just under 4.5% at $14.05 as of publication. The stock’s lackluster performance comes as major indexes pared back gains after skyrocketing on Thursday following the Federal Reserve’s  . Both the S&P 500 and   hit all-time highs Thursday on the news. Both indexes, along with the  , were down less than 1% on Friday. It’s unclear if any insiders have sold any of their shares, but Trump in particular has a lot to gain from selling. The former president  , or just under 115 million shares. Trump’s stake was worth about $1.6 billion on Friday and selling any of it could bring him a major windfall. Despite the golden opportunity, Trump said during a press conference last week that   With that one statement, the stock skyrocketed 27%. Trump Media went public in March through a special purpose acquisition company (SPAC), and since then its share price has fluctuated wildly. The stock often rises and falls based on Trump’s political fortune. Shares shot up after Trump’s first debate with President Joe Biden but have lost more than half of their value since vice president Kamala Harris took over as the Democratic presidential candidate. Moreover, the company’s weak financial performance has experts questioning whether its stock price  . The company brought in just $1.6 million in revenue in the first half of 2024, all while losing more than $300 million over the same period. This story was originally featured on ', 'date': '2024-09-20', 'time': '16:11:59.000', 'link': 'https://finance.yahoo.com/news/trump-media-nosedives-record-low-161159651.html'}
2024-09-21 10:40:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nfl/news/> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:40:51 [rotating_proxies.expire] DEBUG: Proxy <http://20.204.214.79:3129> is DEAD
2024-09-21 10:40:51 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/nfl/news/> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:40:53 [scrapy.extensions.logstats] INFO: Crawled 36 pages (at 2 pages/min), scraped 11 items (at 2 items/min)
2024-09-21 10:40:53 [rotating_proxies.middlewares] INFO: Proxies(good: 20, dead: 10, unchecked: 43, reanimated: 27, mean backoff time: 249s)
2024-09-21 10:40:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nfl/news/> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:40:55 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.164.178:1417> is DEAD
2024-09-21 10:40:55 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/nfl/news/> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:40:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:40:57 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://103.157.117.116:80>
2024-09-21 10:40:57 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:41:01 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html took longer than 360 seconds..
2024-09-21 10:41:01 [rotating_proxies.expire] DEBUG: Proxy <http://149.51.225.130:3128> is DEAD
2024-09-21 10:41:01 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:41:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=TSdZdZo&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fsri-lanka-begins-voting-presidential-013152309.html> from <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html>
2024-09-21 10:41:18 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:41:23 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:41:23 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 10, unchecked: 41, reanimated: 30, mean backoff time: 272s)
2024-09-21 10:41:53 [scrapy.extensions.logstats] INFO: Crawled 36 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:41:53 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 10, unchecked: 41, reanimated: 30, mean backoff time: 272s)
2024-09-21 10:42:23 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 10, unchecked: 41, reanimated: 30, mean backoff time: 272s)
2024-09-21 10:42:53 [scrapy.extensions.logstats] INFO: Crawled 36 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:42:53 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 10, unchecked: 41, reanimated: 30, mean backoff time: 272s)
2024-09-21 10:43:23 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 10, unchecked: 41, reanimated: 30, mean backoff time: 272s)
2024-09-21 10:43:48 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:43:53 [scrapy.extensions.logstats] INFO: Crawled 36 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:43:53 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 9, unchecked: 41, reanimated: 31, mean backoff time: 283s)
2024-09-21 10:43:53 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:44:03 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:44:08 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:44:23 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 6, unchecked: 41, reanimated: 34, mean backoff time: 300s)
2024-09-21 10:44:38 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:44:53 [scrapy.extensions.logstats] INFO: Crawled 36 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:44:53 [rotating_proxies.middlewares] INFO: Proxies(good: 19, dead: 5, unchecked: 41, reanimated: 35, mean backoff time: 313s)
2024-09-21 10:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://guce.yahoo.com/robots.txt> (failed 2 times): User timeout caused connection failure: Getting https://guce.yahoo.com/robots.txt took longer than 360 seconds..
2024-09-21 10:44:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/soccer/news/> (failed 3 times): User timeout caused connection failure: Getting https://sports.yahoo.com/soccer/news/ took longer than 360 seconds..
2024-09-21 10:44:57 [rotating_proxies.expire] DEBUG: Proxy <http://210.61.207.92:80> is DEAD
2024-09-21 10:44:57 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/soccer/news/> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:45:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sports.yahoo.com/soccer/news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:45:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sports.yahoo.com/soccer/news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:45:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nhl/news/> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:45:03 [rotating_proxies.expire] DEBUG: Proxy <http://81.19.141.2:3128> is DEAD
2024-09-21 10:45:03 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/nhl/news/> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:45:07 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html took longer than 360 seconds..
2024-09-21 10:45:07 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://8.148.23.202:9098>
2024-09-21 10:45:07 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:45:08 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:45:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/robots.txt> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:45:15 [rotating_proxies.expire] DEBUG: Proxy <http://103.157.117.116:80> is DEAD
2024-09-21 10:45:15 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/robots.txt> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:45:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html took longer than 360 seconds..
2024-09-21 10:45:17 [rotating_proxies.expire] DEBUG: Proxy <http://190.192.45.168:3128> is DEAD
2024-09-21 10:45:17 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:45:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news took longer than 360 seconds..
2024-09-21 10:45:20 [rotating_proxies.expire] DEBUG: Proxy <http://47.88.31.196:8080> is DEAD
2024-09-21 10:45:20 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:45:23 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:45:23 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 8, unchecked: 39, reanimated: 35, mean backoff time: 275s)
2024-09-21 10:45:23 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:45:23 [rotating_proxies.expire] DEBUG: Proxy <http://67.43.236.22:22079> is DEAD
2024-09-21 10:45:23 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:45:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:45:27 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.172:9739> is DEAD
2024-09-21 10:45:27 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:45:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:45:28 [rotating_proxies.expire] DEBUG: Proxy <http://103.4.167.15:8080> is DEAD
2024-09-21 10:45:28 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:45:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:45:32 [rotating_proxies.expire] DEBUG: Proxy <http://67.43.228.253:12915> is DEAD
2024-09-21 10:45:32 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:45:33 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:45:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:45:34 [rotating_proxies.expire] DEBUG: Proxy <http://117.2.192.50:5006> is DEAD
2024-09-21 10:45:34 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:45:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/robots.txt> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:45:36 [rotating_proxies.expire] DEBUG: Proxy <http://200.41.170.210:11201> is DEAD
2024-09-21 10:45:36 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/robots.txt> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:45:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/robots.txt> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:45:40 [rotating_proxies.expire] DEBUG: Proxy <http://200.60.145.167:8082> is DEAD
2024-09-21 10:45:40 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/robots.txt> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:45:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:45:48 [rotating_proxies.expire] DEBUG: Proxy <http://149.129.255.179:8443> is DEAD
2024-09-21 10:45:48 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:45:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://guce.yahoo.com/robots.txt> (referer: None)
2024-09-21 10:45:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=LcjwSu8&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fmost-people-expect-retire-67-193051193.html> (failed 3 times): Could not open CONNECT tunnel with proxy 123.126.158.50:80 [{'status': 500, 'reason': b'Internal Server Error'}]
2024-09-21 10:45:50 [rotating_proxies.expire] DEBUG: Proxy <http://123.126.158.50:80> is DEAD
2024-09-21 10:45:50 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=LcjwSu8&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fmost-people-expect-retire-67-193051193.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:45:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html took longer than 360 seconds..
2024-09-21 10:45:50 [rotating_proxies.expire] DEBUG: Proxy <http://180.88.111.187:3128> is DEAD
2024-09-21 10:45:50 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:45:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_9b7eb72f-c319-4a44-812c-6f4f4c804509> from <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=FvpeiL8&done=https%3A%2F%2Ffinance.yahoo.com%2Ftopic%2Fstock-market-news%2F>
2024-09-21 10:45:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=Ec4Cv5c&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fbrazil-trims-2024-spending-freeze-002356049.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:45:53 [rotating_proxies.expire] DEBUG: Proxy <http://67.43.228.252:10579> is DEAD
2024-09-21 10:45:53 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=Ec4Cv5c&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fbrazil-trims-2024-spending-freeze-002356049.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:45:53 [scrapy.extensions.logstats] INFO: Crawled 38 pages (at 2 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:45:53 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:45:53 [rotating_proxies.middlewares] INFO: Proxies(good: 18, dead: 17, unchecked: 34, reanimated: 31, mean backoff time: 256s)
2024-09-21 10:45:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> from <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=TSdZdZo&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fsri-lanka-begins-voting-presidential-013152309.html>
2024-09-21 10:45:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:45:55 [rotating_proxies.expire] DEBUG: Proxy <http://43.134.33.254:3128> is DEAD
2024-09-21 10:45:55 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:45:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:45:58 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.92:5635> is DEAD
2024-09-21 10:45:58 [rotating_proxies.middlewares] DEBUG: Gave up retrying <GET https://finance.yahoo.com/news/sri-lankans-vote-presidential-election-013301889.html> (failed 6 times with different proxies)
2024-09-21 10:46:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> from <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=YoASOF0&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fwhy-social-media-companies-keep-183000571.html>
2024-09-21 10:46:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=JqB8EnY&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fwarren-buffett-could-bought-379-090600668.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:46:11 [rotating_proxies.expire] DEBUG: Proxy <http://154.118.229.142:3128> is DEAD
2024-09-21 10:46:11 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=JqB8EnY&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fwarren-buffett-could-bought-379-090600668.html> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:46:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=LcjwSu8&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fmost-people-expect-retire-67-193051193.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:46:11 [rotating_proxies.expire] DEBUG: Proxy <http://27.96.131.193:80> is DEAD
2024-09-21 10:46:11 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=LcjwSu8&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fmost-people-expect-retire-67-193051193.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:46:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:46:11 [rotating_proxies.expire] DEBUG: Proxy <http://27.96.131.193:80> is DEAD
2024-09-21 10:46:11 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:46:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://consent.yahoo.com/robots.txt> (failed 1 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:46:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:46:15 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://43.134.68.153:3128>
2024-09-21 10:46:15 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:46:15 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "guce.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:46:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:46:15 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://85.175.5.50:3128>
2024-09-21 10:46:15 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:46:16 [rotating_proxies.expire] DEBUG: Proxy <http://38.54.116.9:4000> is GOOD
2024-09-21 10:46:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=JqB8EnY&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fwarren-buffett-could-bought-379-090600668.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:46:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=JqB8EnY&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fwarren-buffett-could-bought-379-090600668.html> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:46:23 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 23, unchecked: 33, reanimated: 27, mean backoff time: 251s)
2024-09-21 10:46:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html took longer than 360 seconds..
2024-09-21 10:46:33 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://47.251.87.74:9080>
2024-09-21 10:46:33 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:46:33 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:46:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://finance.yahoo.com/news/brazil-trims-2024-spending-freeze-002356049.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> from <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=Ec4Cv5c&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fbrazil-trims-2024-spending-freeze-002356049.html>
2024-09-21 10:46:38 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:46:40 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "finance.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:46:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_88e902c8-f391-4288-a46e-b033a14457e5> from <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=LcjwSu8&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fmost-people-expect-retire-67-193051193.html>
2024-09-21 10:46:41 [rotating_proxies.expire] DEBUG: Proxy <http://47.238.60.156:80> is GOOD
2024-09-21 10:46:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/brazil-trims-2024-spending-freeze-002356049.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (referer: https://finance.yahoo.com/)
2024-09-21 10:46:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news/brazil-trims-2024-spending-freeze-002356049.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:46:43 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:46:53 [scrapy.extensions.logstats] INFO: Crawled 40 pages (at 2 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:46:53 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 21, unchecked: 32, reanimated: 30, mean backoff time: 276s)
2024-09-21 10:46:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:46:54 [rotating_proxies.expire] DEBUG: Proxy <http://157.66.37.12:8080> is DEAD
2024-09-21 10:46:54 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:46:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nfl/news/> (failed 3 times): User timeout caused connection failure: Getting https://sports.yahoo.com/nfl/news/ took longer than 360 seconds..
2024-09-21 10:46:55 [rotating_proxies.expire] DEBUG: Proxy <http://47.243.92.199:3128> is DEAD
2024-09-21 10:46:55 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/nfl/news/> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:46:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:46:57 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.92:5635> is DEAD
2024-09-21 10:46:57 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:46:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html took longer than 360 seconds..
2024-09-21 10:46:57 [rotating_proxies.expire] DEBUG: Proxy <http://211.104.20.205:8080> is DEAD
2024-09-21 10:46:57 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:47:00 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "sports.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:47:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sports.yahoo.com/nfl/news/> (referer: https://finance.yahoo.com/)
2024-09-21 10:47:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sports.yahoo.com/nfl/news/> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:47:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=M7RoLgI&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fmcdonald-touchscreen-kiosks-were-feared-132749447.html> from <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html>
2024-09-21 10:47:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> from <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=M7RoLgI&done=https%3A%2F%2Ffinance.yahoo.com%2Fnews%2Fmcdonald-touchscreen-kiosks-were-feared-132749447.html>
2024-09-21 10:47:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:47:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:47:18 [rotating_proxies.expire] DEBUG: Proxy <http://43.134.32.184:3128> is DEAD
2024-09-21 10:47:18 [rotating_proxies.middlewares] DEBUG: Gave up retrying <GET https://finance.yahoo.com/news/fake-names-lured-billionaire-salinas-211738755.html> (failed 6 times with different proxies)
2024-09-21 10:47:23 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:47:23 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 24, unchecked: 32, reanimated: 27, mean backoff time: 325s)
2024-09-21 10:47:38 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:47:53 [scrapy.extensions.logstats] INFO: Crawled 41 pages (at 1 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:47:53 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 23, unchecked: 32, reanimated: 28, mean backoff time: 333s)
2024-09-21 10:47:58 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:48:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:48:23 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 21, unchecked: 32, reanimated: 30, mean backoff time: 350s)
2024-09-21 10:48:33 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:48:38 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:48:48 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:48:53 [scrapy.extensions.logstats] INFO: Crawled 41 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:48:53 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 18, unchecked: 32, reanimated: 33, mean backoff time: 378s)
2024-09-21 10:49:08 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:49:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:49:23 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 16, unchecked: 32, reanimated: 35, mean backoff time: 401s)
2024-09-21 10:49:38 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:49:53 [scrapy.extensions.logstats] INFO: Crawled 41 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:49:53 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 14, unchecked: 32, reanimated: 37, mean backoff time: 426s)
2024-09-21 10:49:58 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:50:03 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:50:23 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 11, unchecked: 32, reanimated: 40, mean backoff time: 477s)
2024-09-21 10:50:38 [rotating_proxies.middlewares] DEBUG: 2 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:50:53 [scrapy.extensions.logstats] INFO: Crawled 41 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:50:53 [rotating_proxies.middlewares] INFO: Proxies(good: 17, dead: 9, unchecked: 32, reanimated: 42, mean backoff time: 525s)
2024-09-21 10:51:03 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nhl/news/> (failed 3 times): User timeout caused connection failure: Getting https://sports.yahoo.com/nhl/news/ took longer than 360 seconds..
2024-09-21 10:51:03 [rotating_proxies.expire] DEBUG: Proxy <http://8.216.66.160:3128> is DEAD
2024-09-21 10:51:03 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/nhl/news/> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:51:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html took longer than 360 seconds..
2024-09-21 10:51:17 [rotating_proxies.expire] DEBUG: Proxy <http://149.129.255.179:8443> is DEAD
2024-09-21 10:51:17 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:51:18 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:51:19 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nhl/news/> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:51:19 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://187.157.243.254:8080>
2024-09-21 10:51:19 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/nhl/news/> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:51:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nhl/news/> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:51:22 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.90:1365> is DEAD
2024-09-21 10:51:22 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/nhl/news/> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:51:23 [rotating_proxies.middlewares] INFO: Proxies(good: 16, dead: 11, unchecked: 31, reanimated: 42, mean backoff time: 494s)
2024-09-21 10:51:43 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nhl/news/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:51:43 [rotating_proxies.expire] DEBUG: Proxy <http://158.160.63.194:8090> is DEAD
2024-09-21 10:51:43 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://sports.yahoo.com/nhl/news/> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:51:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news took longer than 360 seconds..
2024-09-21 10:51:48 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://8.209.255.13:3128>
2024-09-21 10:51:48 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:51:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> (failed 2 times): User timeout caused connection failure: Getting https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F took longer than 360 seconds..
2024-09-21 10:51:52 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "finance.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:51:53 [scrapy.extensions.logstats] INFO: Crawled 41 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:51:53 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:51:53 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 12, unchecked: 30, reanimated: 43, mean backoff time: 447s)
2024-09-21 10:51:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news> (referer: https://finance.yahoo.com/)
2024-09-21 10:51:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://finance.yahoo.com/news> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:52:04 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://sports.yahoo.com/nhl/news/> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:52:04 [rotating_proxies.expire] DEBUG: Proxy <http://154.118.229.142:3128> is DEAD
2024-09-21 10:52:04 [rotating_proxies.middlewares] DEBUG: Gave up retrying <GET https://sports.yahoo.com/nhl/news/> (failed 6 times with different proxies)
2024-09-21 10:52:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:52:11 [rotating_proxies.expire] DEBUG: Proxy <http://149.51.225.130:3128> is DEAD
2024-09-21 10:52:11 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:52:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://consent.yahoo.com/robots.txt> (failed 2 times): User timeout caused connection failure: Getting https://consent.yahoo.com/robots.txt took longer than 360 seconds..
2024-09-21 10:52:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb took longer than 360 seconds..
2024-09-21 10:52:15 [rotating_proxies.expire] DEBUG: Proxy <http://27.73.99.242:10004> is DEAD
2024-09-21 10:52:15 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:52:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html took longer than 360 seconds..
2024-09-21 10:52:15 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://190.107.232.138:999>
2024-09-21 10:52:15 [rotating_proxies.middlewares] DEBUG: Gave up retrying <GET https://finance.yahoo.com/news/kids-facing-sudden-wealth-syndrome-193223037.html> (failed 6 times with different proxies)
2024-09-21 10:52:23 [rotating_proxies.middlewares] INFO: Proxies(good: 14, dead: 16, unchecked: 29, reanimated: 41, mean backoff time: 427s)
2024-09-21 10:52:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:52:32 [rotating_proxies.expire] DEBUG: Proxy <http://190.61.90.117:8080> is DEAD
2024-09-21 10:52:32 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:52:33 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:52:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:52:36 [rotating_proxies.expire] DEBUG: Proxy <http://43.134.68.153:3128> is DEAD
2024-09-21 10:52:36 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:52:38 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:52:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:52:53 [rotating_proxies.expire] DEBUG: Proxy <http://62.33.53.248:3128> is DEAD
2024-09-21 10:52:53 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:52:53 [scrapy.extensions.logstats] INFO: Crawled 42 pages (at 1 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:52:53 [rotating_proxies.middlewares] INFO: Proxies(good: 14, dead: 17, unchecked: 28, reanimated: 41, mean backoff time: 441s)
2024-09-21 10:52:55 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:52:55 [rotating_proxies.expire] DEBUG: Proxy <http://117.2.192.50:5006> is DEAD
2024-09-21 10:52:55 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:52:59 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "guce.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:53:01 [rotating_proxies.expire] DEBUG: Proxy <http://8.148.23.202:9098> is GOOD
2024-09-21 10:53:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> (referer: https://finance.yahoo.com/)
2024-09-21 10:53:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://guce.yahoo.com/consent?brandType=nonEu&gcrumb=b7TJTtk&done=https%3A%2F%2Fsports.yahoo.com%2Fnewsletters%2F> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:53:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb took longer than 360 seconds..
2024-09-21 10:53:06 [rotating_proxies.expire] DEBUG: Proxy <http://104.248.98.31:3128> is DEAD
2024-09-21 10:53:06 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:53:23 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 19, unchecked: 27, reanimated: 39, mean backoff time: 429s)
2024-09-21 10:53:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:53:27 [rotating_proxies.expire] DEBUG: Proxy <http://200.41.170.210:11201> is DEAD
2024-09-21 10:53:27 [rotating_proxies.middlewares] DEBUG: Gave up retrying <GET https://finance.yahoo.com/news/mcdonald-touchscreen-kiosks-were-feared-132749447.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (failed 6 times with different proxies)
2024-09-21 10:53:43 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:53:53 [scrapy.extensions.logstats] INFO: Crawled 43 pages (at 1 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:53:53 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 19, unchecked: 27, reanimated: 39, mean backoff time: 442s)
2024-09-21 10:54:08 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:54:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:54:23 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 17, unchecked: 27, reanimated: 41, mean backoff time: 453s)
2024-09-21 10:54:53 [scrapy.extensions.logstats] INFO: Crawled 43 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:54:53 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:54:53 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 16, unchecked: 27, reanimated: 42, mean backoff time: 468s)
2024-09-21 10:55:18 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:55:23 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 15, unchecked: 27, reanimated: 43, mean backoff time: 466s)
2024-09-21 10:55:43 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:55:53 [scrapy.extensions.logstats] INFO: Crawled 43 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:55:53 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 14, unchecked: 27, reanimated: 44, mean backoff time: 458s)
2024-09-21 10:55:58 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:56:03 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:56:08 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:56:23 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 11, unchecked: 27, reanimated: 47, mean backoff time: 498s)
2024-09-21 10:56:28 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:56:33 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:56:53 [scrapy.extensions.logstats] INFO: Crawled 43 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:56:53 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 9, unchecked: 27, reanimated: 49, mean backoff time: 549s)
2024-09-21 10:56:58 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:57:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html took longer than 360 seconds..
2024-09-21 10:57:17 [rotating_proxies.expire] DEBUG: Proxy <http://104.248.98.31:3128> is DEAD
2024-09-21 10:57:17 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:57:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:57:21 [rotating_proxies.expire] DEBUG: Proxy <http://67.43.228.253:12915> is DEAD
2024-09-21 10:57:21 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:57:23 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:57:23 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 9, unchecked: 27, reanimated: 49, mean backoff time: 579s)
2024-09-21 10:57:48 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:57:53 [scrapy.extensions.logstats] INFO: Crawled 43 pages (at 0 pages/min), scraped 11 items (at 0 items/min)
2024-09-21 10:57:53 [rotating_proxies.middlewares] INFO: Proxies(good: 15, dead: 8, unchecked: 27, reanimated: 50, mean backoff time: 570s)
2024-09-21 10:58:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://consent.yahoo.com/robots.txt> (failed 3 times): User timeout caused connection failure: Getting https://consent.yahoo.com/robots.txt took longer than 360 seconds..
2024-09-21 10:58:13 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.164.178:1417> is DEAD
2024-09-21 10:58:13 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://consent.yahoo.com/robots.txt> with another proxy (failed 1 times, max retries: 5)
2024-09-21 10:58:13 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:58:15 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://consent.yahoo.com/robots.txt> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:58:15 [rotating_proxies.expire] DEBUG: Proxy <http://20.219.176.57:3129> is DEAD
2024-09-21 10:58:15 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://consent.yahoo.com/robots.txt> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:58:23 [rotating_proxies.expire] DEBUG: Proxy <http://47.91.65.23:3128> is GOOD
2024-09-21 10:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://consent.yahoo.com/robots.txt> (referer: None)
2024-09-21 10:58:23 [rotating_proxies.middlewares] INFO: Proxies(good: 16, dead: 9, unchecked: 26, reanimated: 49, mean backoff time: 553s)
2024-09-21 10:58:26 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:58:26 [rotating_proxies.expire] DEBUG: Proxy <http://72.10.160.172:9739> is DEAD
2024-09-21 10:58:26 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> with another proxy (failed 2 times, max retries: 5)
2024-09-21 10:58:27 [scrapy.core.downloader.tls] WARNING: Remote certificate is not valid for hostname "consent.yahoo.com"; Certificate does not contain any `subjectAltName`s.
2024-09-21 10:58:28 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_9b7eb72f-c319-4a44-812c-6f4f4c804509> (referer: https://finance.yahoo.com/)
2024-09-21 10:58:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_9b7eb72f-c319-4a44-812c-6f4f4c804509> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:58:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:58:29 [rotating_proxies.expire] DEBUG: Proxy <http://24.57.147.22:8080> is DEAD
2024-09-21 10:58:29 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:58:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (failed 3 times): User timeout caused connection failure: Getting https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb took longer than 360 seconds..
2024-09-21 10:58:36 [rotating_proxies.expire] DEBUG: GOOD proxy became DEAD: <http://31.44.7.32:8080>
2024-09-21 10:58:36 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:58:38 [rotating_proxies.expire] DEBUG: Proxy <http://27.96.131.193:80> is GOOD
2024-09-21 10:58:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html> (referer: https://finance.yahoo.com/)
2024-09-21 10:58:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html>
{'title': 'Intel Gains on Report That Qualcomm Made Takeover Approach', 'content': '(Bloomberg) -- Intel Corp. shares gained nearly 8% after the Wall Street Journal reported that Qualcomm Inc. approached the company about a takeover. Most Read from Bloomberg The discussions occurred in recent days, the newspaper said, citing unnamed people familiar with the situation. Representatives for Intel and Qualcomm declined to comment. The shares jumped as high as $22.81 in New York trading Friday, rebounding from a decline earlier in the day. They had been down 58% this year through Thursday. Most Read from Bloomberg Businessweek ©2024 Bloomberg L.P.', 'date': '2024-09-20', 'time': '19:27:27.000', 'link': 'https://finance.yahoo.com/news/intel-gains-report-qualcomm-made-192727186.html'}
2024-09-21 10:58:40 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (failed 3 times): Connection was refused by other side: 10061: No connection could be made because the target machine actively refused it..
2024-09-21 10:58:40 [rotating_proxies.expire] DEBUG: Proxy <http://66.65.181.6:8080> is DEAD
2024-09-21 10:58:40 [rotating_proxies.middlewares] DEBUG: Gave up retrying <GET https://finance.yahoo.com/news/sri-lanka-begins-voting-presidential-013152309.html?guccounter=1&guce_referrer=aHR0cHM6Ly9maW5hbmNlLnlhaG9vLmNvbS8&guce_referrer_sig=AQAAAIrhG3tJWjA0BJVFo2hvRbC58qQeUlVRO5NmNTw7SpMBRGDuNcdg22h_z64j84iVD8TkrnsfXtGlten8lLH9KvudMoRuBSFh9UMP0IicAvWKnKhRjqvtfec3KidMM2uBcg1n26sdSApkM7aBL8fIFYao2-DEInUKgSxwdEyHozyb> (failed 6 times with different proxies)
2024-09-21 10:58:44 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_88e902c8-f391-4288-a46e-b033a14457e5> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:58:44 [rotating_proxies.expire] DEBUG: Proxy <http://210.61.207.92:80> is DEAD
2024-09-21 10:58:44 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_88e902c8-f391-4288-a46e-b033a14457e5> with another proxy (failed 3 times, max retries: 5)
2024-09-21 10:58:50 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:58:50 [rotating_proxies.expire] DEBUG: Proxy <http://158.160.63.194:8090> is DEAD
2024-09-21 10:58:50 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> with another proxy (failed 4 times, max retries: 5)
2024-09-21 10:58:53 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 3 pages/min), scraped 12 items (at 1 items/min)
2024-09-21 10:58:53 [rotating_proxies.middlewares] INFO: Proxies(good: 16, dead: 14, unchecked: 25, reanimated: 45, mean backoff time: 434s)
2024-09-21 10:58:58 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:59:08 [rotating_proxies.middlewares] DEBUG: 1 proxies moved from 'dead' to 'reanimated'
2024-09-21 10:59:08 [rotating_proxies.expire] DEBUG: Proxy <http://5.189.130.42:23055> is GOOD
2024-09-21 10:59:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_88e902c8-f391-4288-a46e-b033a14457e5> (referer: https://finance.yahoo.com/)
2024-09-21 10:59:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_88e902c8-f391-4288-a46e-b033a14457e5> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:59:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> (failed 3 times): TCP connection timed out: 10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond..
2024-09-21 10:59:11 [rotating_proxies.expire] DEBUG: Proxy <http://35.225.16.82:2387> is DEAD
2024-09-21 10:59:11 [rotating_proxies.middlewares] DEBUG: Retrying <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> with another proxy (failed 5 times, max retries: 5)
2024-09-21 10:59:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> (referer: https://finance.yahoo.com/)
2024-09-21 10:59:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://consent.yahoo.com/v2/collectConsent?sessionId=3_cc-session_14ce1654-d488-43e7-9a5d-a564aeb8f561> (referer: https://finance.yahoo.com/)
Traceback (most recent call last):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\utils\asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\core\spidermw.py", line 118, in process_async
    async for r in iterable:
  File "C:\Users\Admin\anaconda3\envs\stock_chatbot\lib\site-packages\scrapy\spiders\crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Admin\Github repos\Playground\python\crawler\crawl_yahoo\crawl_yahoo\spiders\yahoo_crawler.py", line 18, in parse_item
    date, time = response.css("time::attr(datetime)").get().split("T")
AttributeError: 'NoneType' object has no attribute 'split'
2024-09-21 10:59:17 [scrapy.core.engine] INFO: Closing spider (finished)
2024-09-21 10:59:17 [scrapy.extensions.feedexport] INFO: Stored json feed (12 items) in: output_20240921_102452.json
2024-09-21 10:59:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'bans/error/scrapy.core.downloader.handlers.http11.TunnelError': 8,
 'bans/error/twisted.internet.error.ConnectionRefusedError': 36,
 'bans/error/twisted.internet.error.TCPTimedOutError': 34,
 'bans/error/twisted.internet.error.TimeoutError': 22,
 'bans/error/twisted.web._newclient.ResponseNeverReceived': 3,
 'bans/status/403': 2,
 'bans/status/404': 1,
 'downloader/exception_count': 197,
 'downloader/exception_type_count/scrapy.core.downloader.handlers.http11.TunnelError': 13,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 9,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 61,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 62,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 39,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 2,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 11,
 'downloader/request_bytes': 158185,
 'downloader/request_count': 252,
 'downloader/request_method_count/GET': 252,
 'downloader/response_bytes': 7299905,
 'downloader/response_count': 64,
 'downloader/response_status_count/200': 47,
 'downloader/response_status_count/302': 6,
 'downloader/response_status_count/307': 8,
 'downloader/response_status_count/403': 2,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 2063.743877,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 9, 21, 3, 59, 17, 42724, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 35282973,
 'httpcompression/response_count': 28,
 'item_scraped_count': 12,
 'log_count/DEBUG': 492,
 'log_count/ERROR': 132,
 'log_count/INFO': 115,
 'log_count/WARNING': 20,
 'proxies/dead': 13,
 'proxies/good': 17,
 'proxies/mean_backoff': 418.07487497927434,
 'proxies/reanimated': 46,
 'proxies/unchecked': 24,
 'request_depth_max': 1,
 'response_received_count': 48,
 'retry/count': 85,
 'retry/max_reached': 103,
 'retry/reason_count/scrapy.core.downloader.handlers.http11.TunnelError': 5,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 25,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 28,
 'retry/reason_count/twisted.internet.error.TimeoutError': 17,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 2,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 8,
 "robotstxt/exception_count/<class 'twisted.internet.error.ConnectionRefusedError'>": 1,
 'robotstxt/forbidden': 9,
 'robotstxt/request_count': 7,
 'robotstxt/response_count': 6,
 'robotstxt/response_status_count/200': 6,
 'scheduler/dequeued': 230,
 'scheduler/dequeued/memory': 230,
 'scheduler/enqueued': 230,
 'scheduler/enqueued/memory': 230,
 'spider_exceptions/AttributeError': 28,
 'start_time': datetime.datetime(2024, 9, 21, 3, 24, 53, 298847, tzinfo=datetime.timezone.utc)}
2024-09-21 10:59:17 [scrapy.core.engine] INFO: Spider closed (finished)
